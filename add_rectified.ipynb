{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the rectified images together and write out as a fits file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "from astropy.io import ascii, fits\n",
    "from astropy.visualization import MinMaxInterval, AsinhStretch, HistEqStretch, ImageNormalize\n",
    "from scipy import interpolate\n",
    "from scipy.optimize import curve_fit\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_alignment(source, path, fitsfiles, order=106):\n",
    "\n",
    "    j1 = 30           # starting point of first order -- figured out by hand\n",
    "    dj_AB = 121       # width of each order -- this should match the size of the number of rows in the order extension\n",
    "    dj_blank = 30     # gap between orders -- this is figured out by eye and assumed to be the same for all orders\n",
    "    j0 = j1 + (dj_AB + dj_blank) * (order - 99)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    ax.set_xlabel(r\"Row (pixels)\", fontsize=12)\n",
    "    ax.set_ylabel(r\"Flux (Jy)\", fontsize=12)\n",
    "    plt.suptitle(source)\n",
    "    for n, f in enumerate(fitsfiles):\n",
    "        hdu = fits.open(path+f)\n",
    "        flux = hdu[0].data\n",
    "        var = hdu[1].data\n",
    "        hdu.close()\n",
    "\n",
    "        order_flux = flux[j0:j0+dj_AB, :]\n",
    "        im_median = np.nanmedian(order_flux, axis=1)\n",
    "        ax.plot(np.arange(im_median.size), im_median, label=f.strip('rectified').strip('.fits'))\n",
    "\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path+source+'_alignment.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(path, fitsfiles):\n",
    "\n",
    "    for n, f in enumerate(fitsfiles):\n",
    "        hdu = fits.open(path+f)\n",
    "        flux = hdu[0].data\n",
    "        var = hdu[1].data\n",
    "        hdu.close()\n",
    "\n",
    "        w = 1 / var\n",
    "        if n == 0:\n",
    "            flux_sum = w * flux\n",
    "            weights_sum = w\n",
    "        else:\n",
    "            flux_sum += w * flux\n",
    "            weights_sum += w\n",
    "\n",
    "    return flux_sum/weights_sum, 1/weights_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined_image(source, flux, var):\n",
    "    fig = plt.figure(figsize=(12, 7))\n",
    "\n",
    "    ax1 = plt.subplot(121)\n",
    "    #flux_norm = ImageNormalize(flux, interval=MinMaxInterval(), stretch=HistEqStretch(flux))\n",
    "    flux_norm = ImageNormalize(flux, vmin=-5, vmax=5, stretch=AsinhStretch(0.3))\n",
    "    ax1.imshow(flux, origin='lower', norm=flux_norm)\n",
    "    ax1.set_title('Combined Flux')\n",
    "\n",
    "    ax2 = plt.subplot(122)\n",
    "    var_norm = ImageNormalize(var, interval=MinMaxInterval(), stretch=HistEqStretch(var))\n",
    "    ax2.imshow(var, origin='lower', norm=var_norm)\n",
    "    ax2.set_title('Combined Variance')\n",
    "\n",
    "    plt.suptitle(source)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path+source+'_combined.png')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_combined_fits(source, path, fitsfiles, flux, var):\n",
    "    # write out the combined data as a fits file\n",
    "\n",
    "    # just use the same header as one of the rectified fits files\n",
    "    # TBD: include more metadata about what is being combined\n",
    "    hdu = fits.open(path+fitsfiles[0])\n",
    "    hd0 = hdu[0].header\n",
    "    hdu.close()\n",
    "\n",
    "    hdu_flux = fits.PrimaryHDU(flux, header=hd0)\n",
    "    hdu_var = fits.ImageHDU(var)\n",
    "    hdu_list = fits.HDUList([hdu_flux, hdu_var])\n",
    "    hdu_list.writeto(path+source+'_rectified.fits')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# read in the set of rectified files to be combined source by source\n",
    "# you have to manually create sourcefile.txt in the same directory as the rectified fits files\n",
    "\n",
    "path = '/Volumes/JPW_4TB/iSHELL/191008/rectified/'\n",
    "with open(path+'sourcelist.txt') as f:\n",
    "    all_lines = f.read()\n",
    "lines = all_lines.split('\\n')\n",
    "\n",
    "# find the breakpoints between sources\n",
    "nbreak = []\n",
    "for nline, line1 in enumerate(lines):\n",
    "    if line1[0:4] == '----':\n",
    "        nbreak.append(nline)\n",
    "\n",
    "# read in the source and the associated list of rectified files to combine\n",
    "for n1 in range(len(nbreak)-1):\n",
    "    source = lines[nbreak[n1]+1]\n",
    "    fitsfiles = []\n",
    "    for n2 in range(nbreak[n1]+2, nbreak[n1+1]):\n",
    "        fitsfiles.append(lines[n2])\n",
    "\n",
    "    #check_alignment(source, path, fitsfiles, order=106)\n",
    "    flux, var = weighted_average(path, fitsfiles)\n",
    "    plot_combined_image(source, flux, var)\n",
    "    write_combined_fits(source, path, fitsfiles, flux, var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
