{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/jpw/py/spectools_ir/')\n",
    "import spectools_ir\n",
    "from spectools_ir.utils import extract_hitran_data, spec_convol_R\n",
    "from astropy.table import Table, vstack\n",
    "\n",
    "from astropy.io import ascii, fits\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import pandas as pd\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter,\n",
    "                               AutoMinorLocator)\n",
    "\n",
    "#Asys.path.append('/Users/pietro/PhD/Work/iSHELL_spectroastrometry/')\n",
    "#from shift_vel_mine import CalShift\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "source = 'HLTau'\n",
    "prop = pd.read_csv(f'disk_properties.csv', skipinitialspace=True)\n",
    "PA1 = prop[source][0]\n",
    "PA2 = PA1+180\n",
    "\n",
    "# From Adwin\n",
    "v_geo_Ad = prop[source][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '240107'\n",
    "path = '/Users/jpw/Analysis/NIRSPEC/iSHELL/'+date+'/'\n",
    "source = 'HLTau'\n",
    "PA1 = 48\n",
    "\n",
    "source = 'CWTau'\n",
    "PA1 = 61\n",
    "\n",
    "date = '230630'\n",
    "path = '/Volumes/JPW_2TB/iSHELL/'+date+'/'\n",
    "source = 'Elias24'\n",
    "PA1 = 136\n",
    "\n",
    "PA2 = PA1 + 180\n",
    "v_geo_Ad = -10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Volumes/JPW_2TB/iSHELL/240107/reduced/Elias24_flux_combined_PA136_316.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tx/plmj8k8969gcvbqj4tml5hvm0000gn/T/ipykernel_24081/3118415777.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtable1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf'reduced/{source}_flux_combined_PA{PA1}_{PA2}.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipinitialspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwave_flux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wavelength'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwave_flux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwave_flux\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwave_flux\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mv_geo_Ad\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m299792\u001b[0m    \u001b[0;31m# Correcting for motion relative to Earth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mflux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'flux'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0merr_flux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'err_flux'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Volumes/JPW_2TB/iSHELL/240107/reduced/Elias24_flux_combined_PA136_316.csv'"
     ]
    }
   ],
   "source": [
    "table1 = pd.read_csv(path + f'reduced/{source}_flux_combined_PA{PA1}_{PA2}.csv', skipinitialspace=True)\n",
    "wave_flux = table1['wavelength']\n",
    "wave_flux = wave_flux - wave_flux*v_geo_Ad/299792    # Correcting for motion relative to Earth\n",
    "flux = table1['flux']\n",
    "err_flux = table1['err_flux']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.plot(wave_flux, flux, lw=1, color='b')\n",
    "plt.fill_between(wave_flux, flux-err_flux, flux+err_flux, alpha=0.5, color='b')\n",
    "\n",
    "ax.set_xlabel(r'$\\lambda$ ($\\mu$m)', fontsize = 20, labelpad=10)\n",
    "ax.set_ylabel('Flux(Jy)', fontsize = 20, labelpad=10)\n",
    "#ax.set_ylim(-0.5, 0.5)\n",
    "#ax.set_xlim(4.7,4.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_filter(arr, arr_err, w):\n",
    "    # Median filter 1D array arr over a window size w in pixels\n",
    "\n",
    "    n = arr.size\n",
    "    arr_filter, arr_fiter_err = np.zeros(n), np.zeros(n)\n",
    "    \n",
    "    # Define the window\n",
    "    for i in range(n):\n",
    "        \n",
    "        # Left edge\n",
    "        if i<int((w-1)/2):\n",
    "            arr_window = arr[:i+1+int((w-1)/2)] \n",
    "        # Central pixels\n",
    "        if int((w-1)/2)<= i < int(n - (w-1)/2):\n",
    "            arr_window = arr[i-int((w-1)/2):i+1+int((w-1)/2)]\n",
    "        # Right edge\n",
    "        if i>=int(n - (w-1)/2):\n",
    "            arr_window = arr[i-int((w-1)/2):] \n",
    "            \n",
    "        arr_filter[i] = np.nanmedian(arr_window)\n",
    "        arr_fiter_err[i] = 1.253 * arr_err[i]/np.sqrt(arr_window.size)\n",
    "    \n",
    "    return arr_filter, arr_fiter_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Normalization of the spectrum #####\n",
    "# We first sigma clip, then apply the median filter to the clipped data\n",
    "\n",
    "from astropy.stats import sigma_clip\n",
    "filtered_data = sigma_clip(flux, sigma=1.7, maxiters=10, masked=False, axis=0, cenfunc='median', stdfunc='mad_std')\n",
    "for j in range(8):\n",
    "    fig = plt.figure(figsize=(14, 3))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    plt.plot(wave_flux, filtered_data, lw=1, color='b')\n",
    "    #plt.fill_between(wave_flux, flux-err_flux, flux+err_flux, alpha=0.5, color='b')\n",
    "\n",
    "    #plt.scatter(wave_flux, flux_filter, lw=1, color='orange', zorder=2, s=1)\n",
    "\n",
    "    ax.set_xlabel(r'$\\lambda$ ($\\mu$m)', fontsize = 20, labelpad=10)\n",
    "    ax.set_ylabel('Flux(Jy)', fontsize = 20, labelpad=10)\n",
    "    #ax.set_ylim(2, 7)\n",
    "    ax.set_xlim(4.5+j/10,4.6+j/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_width = 500 # pixels \n",
    "flux_filter, flux_filter_err = median_filter(filtered_data, err_flux, window_width)\n",
    "flux_norm = flux/flux_filter\n",
    "err_flux_norm = err_flux/flux_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 3))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.plot(wave_flux, flux, lw=1, color='b')\n",
    "plt.fill_between(wave_flux, flux-err_flux, flux+err_flux, alpha=0.5, color='b')\n",
    "\n",
    "pixel_wave_size = (wave_flux.max()- wave_flux.min())/wave_flux.size\n",
    "ax.axvline(4.72, color='gray', ls='--')\n",
    "ax.axvline(4.72+window_width*pixel_wave_size, color='gray', ls='--')\n",
    "\n",
    "\n",
    "ax.set_xlabel(r'$\\lambda$ ($\\mu$m)', fontsize = 20, labelpad=10)\n",
    "ax.set_ylabel('Flux(Jy)', fontsize = 20, labelpad=10)\n",
    "#ax.set_ylim(-0.5, 0.5)\n",
    "ax.set_xlim(4.7,4.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for j in range(8):\n",
    "    fig = plt.figure(figsize=(14, 3))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    plt.plot(wave_flux, flux, lw=1, color='b')\n",
    "    plt.fill_between(wave_flux, flux-err_flux, flux+err_flux, alpha=0.5, color='b')\n",
    "\n",
    "    plt.scatter(wave_flux, flux_filter, lw=1, color='orange', zorder=2, s=1)\n",
    "\n",
    "    ax.set_xlabel(r'$\\lambda$ ($\\mu$m)', fontsize = 20, labelpad=10)\n",
    "    ax.set_ylabel('Flux(Jy)', fontsize = 20, labelpad=10)\n",
    "    ax.set_ylim(0, 4)\n",
    "    ax.set_xlim(4.5+j/10,4.6+j/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.plot(wave_flux, flux/flux_filter, lw=1, color='b', label='Normalized spectrum')\n",
    "#plt.fill_between(wave_flux, flux/flux_filter-err_flux/flux_filter, flux/flux_filter+err_flux/flux_filter, alpha=0.2, color='b')\n",
    "\n",
    "plt.plot(wave_flux, (flux-np.mean(flux_filter))/np.mean(flux_filter)+1, lw=1, color='r', alpha=0.5, zorder=0, label='Rescaled old spectrum')\n",
    "\n",
    "ax.axhline(1, color='gray', linestyle='dashed')\n",
    "ax.legend(fontsize=15)\n",
    "\n",
    "ax.set_xlabel(r'$\\lambda$ ($\\mu$m)', fontsize = 20, labelpad=10)\n",
    "ax.set_ylabel('Normalized flux', fontsize = 20, labelpad=10)\n",
    "ax.set_ylim(0., 2)\n",
    "#ax.set_xlim(4.7,4.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(8):\n",
    "    fig = plt.figure(figsize=(14, 3))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    plt.plot(wave_flux, flux_norm, lw=1, color='b')\n",
    "    plt.fill_between(wave_flux, flux_norm-err_flux_norm, flux_norm+err_flux_norm, alpha=0.5, color='b')\n",
    "\n",
    "    ax.axhline(1, color='gray', linestyle='dashed')\n",
    "    ax.set_xlabel(r'$\\lambda$ ($\\mu$m)', fontsize = 20, labelpad=10)\n",
    "    ax.set_ylabel('Flux(Jy)', fontsize = 20, labelpad=10)\n",
    "    ax.set_ylim(0.5, 1.5)\n",
    "    ax.set_xlim(4.5+j/10,4.6+j/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 3))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.plot(wave_flux, flux_norm, lw=1, color='b')\n",
    "plt.fill_between(wave_flux, flux_norm-err_flux_norm, flux_norm+err_flux_norm, alpha=0.2, color='b')\n",
    "\n",
    "ax.axhline(1, color='gray', linestyle='dashed')\n",
    "\n",
    "ax.set_xlabel(r'$\\lambda$ ($\\mu$m)', fontsize = 20, labelpad=10)\n",
    "ax.set_ylabel('Normalized flux', fontsize = 20, labelpad=10)\n",
    "ax.set_ylim(0.8, 1.3)\n",
    "ax.set_xlim(4.7,4.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SA (in mas)\n",
    "SA_table = pd.read_csv(path+f'rectified/{source}_SA_combined_PA{PA1}_{PA2}.csv', skipinitialspace=True)\n",
    "wave_SA = SA_table['wavelength']\n",
    "wave_SA = wave_SA - wave_SA*v_geo_Ad/299792    # Correcting for motion relative to Earth\n",
    "SA = SA_table['SA']\n",
    "err_SA = SA_table['err_SA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = open(path+f'reduced/{source}_flux_combined_PA{PA1}_{PA2}_shifted.csv', 'w')\n",
    "csvfile.write('wave_flux,  flux, err_flux\\n')\n",
    "\n",
    "for i in range(wave_flux.size):\n",
    "    csvfile.write(f'{wave_flux[i]:11.9f}, {flux_norm[i]:.5f}, {err_flux_norm[i]:.5f}\\n')\n",
    "    \n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = open(path+f'rectified/{source}_SA_combined_PA{PA1}_{PA2}_shifted.csv', 'w')\n",
    "csvfile.write('wave_SA, SA, err_SA\\n')\n",
    "\n",
    "for i in range(wave_SA.size):\n",
    "    csvfile.write(f'{wave_SA[i]:11.9f}, {SA[i]:.5f}, {err_SA[i]:.5f}\\n')\n",
    "    \n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking 12CO v=1-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitran_CO_1_0 = extract_hitran_data('CO', np.nanmin(wave_flux)-np.nanmin(wave_flux)*0.001, np.nanmax(wave_flux)+np.nanmax(wave_flux)*0.001, vup=1)\n",
    "hitran_CO_2_1 = extract_hitran_data('CO', np.nanmin(wave_flux)-np.nanmin(wave_flux)*0.001, np.nanmax(wave_flux)+np.nanmax(wave_flux)*0.001, vup=2)\n",
    "hitran_13CO_1_0 = extract_hitran_data('CO', np.nanmin(wave_flux)-np.nanmin(wave_flux)*0.001, np.nanmax(wave_flux)+np.nanmax(wave_flux)*0.001, isotopologue_number=2, vup=1)\n",
    "\n",
    "hitran_CO_1_0.sort('wave')\n",
    "hitran_CO_2_1.sort('wave')\n",
    "hitran_13CO_1_0.sort('wave')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowJ = ['P5', 'P6', 'P7', 'P8', 'P9', 'P10', 'P11', 'P12', 'P13', 'P14', 'P15', 'P16', 'P17', 'P18'\n",
    "        'R5', 'R6', 'R7', 'R8', 'R9', 'R10', 'R11', 'R12', 'R13', 'R14', 'R15', 'R16', 'R17', 'R18'] \n",
    "\n",
    "#highJ = ['P25', 'P26', 'P27', 'P28', 'P29', 'P30', 'P31']\n",
    "highJ = ['P25', 'P26', 'P27', 'P28', 'P29', 'P30', 'P31', 'P32', 'P33', 'P34', 'P35', 'P36', 'P37', 'P38', 'P39', 'P40', 'P41', 'P42']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wavelength range over which to look for lines\n",
    "wave_range = (np.nanmin(wave_flux)-np.nanmin(wave_flux)*0.001, np.nanmax(wave_flux)+np.nanmax(wave_flux)*0.001)\n",
    "\n",
    "# wavelength window (in microns) around the line to look for data (roughly corresponds to +/-30 km/s)\n",
    "delta_wave_signal = 5e-4\n",
    "\n",
    "# find the transitions where there is some signal\n",
    "trans_nums = 0\n",
    "trans_wave = []\n",
    "trans_ids = []\n",
    "for i, wave1 in enumerate(hitran_CO_1_0['wave']):\n",
    "    if hitran_CO_1_0['Qpp'][i].replace(' ','') in lowJ:\n",
    "        if ((wave1 > wave_range[0]) & (wave1 < wave_range[1])):\n",
    "            # Select indices around the transitions\n",
    "            j = np.where((wave_flux > wave1-delta_wave_signal) & (wave_flux < wave1+delta_wave_signal))[0]\n",
    "            # Accept and save transitions and their ids for where we have signal (not everything is NaN)\n",
    "            if np.sum(np.isfinite(flux[j])) > 0:\n",
    "                trans_nums += 1\n",
    "                trans_wave.append(wave1)\n",
    "                trans_ids.append(hitran_CO_1_0['Qpp'][i].replace(' ',''))\n",
    "            \n",
    "            \n",
    "# take snippets of each transition from +/-delta_v in km/s, sampled at 1 km/s\n",
    "# ~10% wider in wavelength to avoid interpolation issues\n",
    "delta_v = 120\n",
    "clight = 2.99792458e5\n",
    "delta_wave = 1.1 * 5 * delta_v / clight\n",
    "\n",
    "v_spec = np.arange(-delta_v, 1.01*delta_v, 1)\n",
    "nv = v_spec.size\n",
    "flux_stack_lowJ = np.zeros(nv)\n",
    "weights_stack_flux_lowJ = np.zeros(nv)\n",
    "    \n",
    "nrows = 8\n",
    "ncols = math.ceil(trans_nums / nrows)\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(18, 18))\n",
    "\n",
    "print(f'Stacking transitions:', end=' ')\n",
    "for i, wave1 in enumerate(trans_wave):\n",
    "    #print(i, wave1)\n",
    "    col = i % ncols\n",
    "    row = int(i / ncols)\n",
    "\n",
    "    j = np.where((wave_flux > wave1-delta_wave) & (wave_flux < wave1+delta_wave))[0]\n",
    "    v_wave = (wave_flux[j] / wave1 - 1) * clight\n",
    "    wave_plot = wave_flux[j]\n",
    "\n",
    "    flux_v = interp1d(v_wave, flux_norm[j], bounds_error=False)\n",
    "    flux_err = interp1d(v_wave, err_flux_norm[j], bounds_error=False)\n",
    "    #axs[row, col].plot(v_spec, flux_v(v_spec), color='b')\n",
    "    #axs[row, col].set_xlim(-delta_v, delta_v)\n",
    "\n",
    "    axs[row, col].plot(wave_plot, flux_norm[j], color='darkblue')\n",
    "    axs[row, col].set_xlim(wave1-delta_wave, wave1+delta_wave)\n",
    "    axs[row, col].axvline(wave1, color='C1', ls = '--')\n",
    "    axs[row, col].text(wave1+0.03*delta_wave, 0.6, trans_ids[i], rotation=90, fontsize=12, fontweight='bold', color='C1')\n",
    "\n",
    "    # plot any 13CO v=1-0 transitions within delta_wave of the 13CO line\n",
    "    for k, wave_CO10 in enumerate(hitran_13CO_1_0['wave']):\n",
    "        if np.abs(wave_CO10 - wave1) < delta_wave:\n",
    "            axs[row, col].axvline(wave_CO10, color='green', ls=':')\n",
    "            axs[row, col].text(wave_CO10+0.03*delta_wave, 0.6, hitran_CO_1_0['Qpp'][i].replace(' ',''), color='green', rotation=90)\n",
    "    #axs[row, col].set_ylim(0.2, 1.4)\n",
    "\n",
    "    # plot any CO v=2-1 transitions within delta_wave of the 13CO line\n",
    "    for k, wave_CO21 in enumerate(hitran_CO_2_1['wave']):\n",
    "        if np.abs(wave_CO21 - wave1) < delta_wave:\n",
    "            axs[row, col].axvline(wave_CO21, color='cyan', ls=':')\n",
    "            axs[row, col].text(wave_CO21+0.03*delta_wave, 0.6, hitran_CO_2_1['Qpp'][i].replace(' ',''), color='cyan', rotation=90)\n",
    "    #axs[row, col].set_ylim(0.2, 1.4)\n",
    "\n",
    "    # stacking without counting the NaNs\n",
    "    # do not include the following 13CO transitions since they are contaminated by some CO v=1-0 transitions\n",
    "    #bad_trans_v10 = ['R38','R35','R34','R33','R30','R29','R26','R25','R24','R21','R20','R19','R15','R14','R9','R8','R7','R2','R1','R0','P6','P13','P14','P15','P22','P23','P24','P33','P34']\n",
    "    #bad_trans_v21 = []\n",
    "    #bad_trans = bad_trans_v10 + bad_trans_v21\n",
    "    #if trans_ids[i] not in bad_trans:\n",
    "    \n",
    "    print(f'{trans_ids[i]},', end=' ')\n",
    "    # stacking without counting the NaNs\n",
    "    for j, v1 in enumerate(v_spec):\n",
    "        f = flux_v(v1)\n",
    "        e = flux_err(v1)\n",
    "        if np.isfinite(f) & np.isfinite(e):\n",
    "            w = 1/e**2\n",
    "            flux_stack_lowJ[j] = flux_stack_lowJ[j] + w * f\n",
    "            weights_stack_flux_lowJ[j] = weights_stack_flux_lowJ[j] + w\n",
    "\n",
    "    axs[row, col].set_ylim(0.5, 1.5)\n",
    "    #axs[row, col].axhline(1, color='k', ls=':')\n",
    "    axs[row, col].set_xlabel(r'$\\lambda$ ($\\mu$m)')\n",
    "    if col == 0:\n",
    "        axs[row, col].set_ylabel('Normalized flux')\n",
    "\n",
    "print(f'\\n')\n",
    "\n",
    "# don't show axes for panels where there is no data\n",
    "n_extra = nrows * ncols - len(trans_wave)\n",
    "if n_extra > 0:\n",
    "    for i in range(n_extra):\n",
    "        col = (nrows*ncols - i - 1) % ncols\n",
    "        row = int((nrows*ncols - i - 1) / ncols)\n",
    "        axs[row, col].axis('off')\n",
    "\n",
    "#plt.savefig('transitions.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# wavelength range over which to look for lines\n",
    "wave_range = (np.nanmin(wave_SA)-np.nanmin(wave_SA)*0.001, np.nanmax(wave_SA)+np.nanmax(wave_SA)*0.001)\n",
    "\n",
    "# wavelength window (in microns) around the line to look for data (roughly corresponds to +/-30 km/s)\n",
    "delta_wave_signal = 5e-4\n",
    "\n",
    "# find the transitions where there is some signal\n",
    "trans_nums = 0\n",
    "trans_wave = []\n",
    "trans_ids = []\n",
    "for i, wave1 in enumerate(hitran_CO_1_0['wave']):\n",
    "    if hitran_CO_1_0['Qpp'][i].replace(' ','') in lowJ:\n",
    "        if ((wave1 > wave_range[0]) & (wave1 < wave_range[1])):\n",
    "            # Select indices around the transitions\n",
    "            j = np.where((wave_SA > wave1-delta_wave_signal) & (wave_SA < wave1+delta_wave_signal))[0]\n",
    "            # Accept and save transitions and their ids for where we have signal (not everything is NaN)\n",
    "            if np.sum(np.isfinite(SA[j])) > 0:\n",
    "                trans_nums += 1\n",
    "                trans_wave.append(wave1)\n",
    "                trans_ids.append(hitran_CO_1_0['Qpp'][i].replace(' ',''))\n",
    "            \n",
    "# take snippets of each transition from +/-delta_v in km/s, sampled at 1 km/s\n",
    "# ~10% wider in wavelength to avoid interpolation issues\n",
    "delta_v = 120\n",
    "clight = 2.99792458e5\n",
    "delta_wave = 1.1 * 5 * delta_v / clight\n",
    "\n",
    "v_spec = np.arange(-delta_v, 1.01*delta_v, 1)\n",
    "nv = v_spec.size\n",
    "SA_stack_lowJ = np.zeros(nv)\n",
    "weights_stack_SA_lowJ = np.zeros(nv)\n",
    "    \n",
    "nrows = 8\n",
    "ncols = math.ceil(trans_nums / nrows)\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(18, 18))\n",
    "\n",
    "print(f'Stacking transitions:', end=' ')\n",
    "for i, wave1 in enumerate(trans_wave):\n",
    "    #print(i, wave1)\n",
    "    col = i % ncols\n",
    "    row = int(i / ncols)\n",
    "\n",
    "    j = np.where((wave_SA > wave1-delta_wave) & (wave_SA < wave1+delta_wave))[0]\n",
    "    v_wave = (wave_SA[j] / wave1 - 1) * clight\n",
    "    wave_plot = wave_SA[j]\n",
    "\n",
    "    SA_v = interp1d(v_wave, SA[j], bounds_error=False)\n",
    "    SA_err = interp1d(v_wave, err_SA[j], bounds_error=False)\n",
    "    #axs[row, col].plot(v_spec, SA_v(v_spec), color='b')\n",
    "    #axs[row, col].set_xlim(-delta_v, delta_v)\n",
    "\n",
    "    axs[row, col].plot(wave_plot, SA[j], color='k')\n",
    "    axs[row, col].set_xlim(wave1-delta_wave, wave1+delta_wave)\n",
    "    axs[row, col].axvline(wave1, color='C1', ls = '--')\n",
    "    axs[row, col].text(wave1+0.03*delta_wave, 0.6, trans_ids[i], rotation=90, fontsize=12, fontweight='bold', color='C1')\n",
    "\n",
    "    # plot any 13CO v=1-0 transitions within delta_wave of the 13CO line\n",
    "    for k, wave_CO10 in enumerate(hitran_13CO_1_0['wave']):\n",
    "        if np.abs(wave_CO10 - wave1) < delta_wave:\n",
    "            axs[row, col].axvline(wave_CO10, color='green', ls=':')\n",
    "            axs[row, col].text(wave_CO10+0.03*delta_wave, 0.6, hitran_CO_1_0['Qpp'][i].replace(' ',''), color='green', rotation=90)\n",
    "    #axs[row, col].set_ylim(0.2, 1.4)\n",
    "\n",
    "    # plot any CO v=2-1 transitions within delta_wave of the 13CO line\n",
    "    for k, wave_CO21 in enumerate(hitran_CO_2_1['wave']):\n",
    "        if np.abs(wave_CO21 - wave1) < delta_wave:\n",
    "            axs[row, col].axvline(wave_CO21, color='cyan', ls=':')\n",
    "            axs[row, col].text(wave_CO21+0.03*delta_wave, 0.6, hitran_CO_2_1['Qpp'][i].replace(' ',''), color='cyan', rotation=90)\n",
    "    #axs[row, col].set_ylim(0.2, 1.4)\n",
    "\n",
    "    # stacking without counting the NaNs\n",
    "    # do not include the following 13CO transitions since they are contaminated by some CO v=1-0 transitions\n",
    "    #bad_trans_v10 = ['R38','R35','R34','R33','R30','R29','R26','R25','R24','R21','R20','R19','R15','R14','R9','R8','R7','R2','R1','R0','P6','P13','P14','P15','P22','P23','P24','P33','P34']\n",
    "    #bad_trans_v21 = []\n",
    "    #bad_trans = bad_trans_v10 + bad_trans_v21\n",
    "    #if trans_ids[i] not in bad_trans:\n",
    "    \n",
    "    print(f'{trans_ids[i]},', end=' ')\n",
    "    # stacking without counting the NaNs\n",
    "    for j, v1 in enumerate(v_spec):\n",
    "        f = SA_v(v1)\n",
    "        e = SA_err(v1)\n",
    "        if np.isfinite(f) & np.isfinite(e):\n",
    "            w = 1/e**2\n",
    "            SA_stack_lowJ[j] = SA_stack_lowJ[j] + w * f\n",
    "            weights_stack_SA_lowJ[j] = weights_stack_SA_lowJ[j] + w\n",
    "\n",
    "    axs[row, col].set_ylim(-20, 20)\n",
    "    #axs[row, col].axhline(1, color='k', ls=':')\n",
    "    axs[row, col].set_xlabel(r'$\\lambda$ ($\\mu$m)')\n",
    "    if col == 0:\n",
    "        axs[row, col].set_ylabel('SA (mas)')\n",
    "\n",
    "print(f'\\n')\n",
    "\n",
    "# don't show axes for panels where there is no data\n",
    "n_extra = nrows * ncols - len(trans_wave)\n",
    "if n_extra > 0:\n",
    "    for i in range(n_extra):\n",
    "        col = (nrows*ncols - i - 1) % ncols\n",
    "        row = int((nrows*ncols - i - 1) / ncols)\n",
    "        axs[row, col].axis('off')\n",
    "\n",
    "#plt.savefig('transitions.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_stacked_lowJ = flux_stack_lowJ / weights_stack_flux_lowJ\n",
    "err_flux_stacked_lowJ = 1/np.sqrt(weights_stack_flux_lowJ)\n",
    "\n",
    "SA_stacked_lowJ = SA_stack_lowJ / weights_stack_SA_lowJ\n",
    "err_SA_stacked_lowJ = 1/np.sqrt(weights_stack_SA_lowJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0., hspace=0.07)\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.plot(v_spec, flux_stacked_lowJ, color='mediumblue', lw=2)\n",
    "ax1.fill_between(v_spec, flux_stacked_lowJ - err_flux_stacked_lowJ, flux_stacked_lowJ + err_flux_stacked_lowJ, color='mediumblue', alpha=0.3)\n",
    "#ax.set_xlabel('Velocity (km/s)')\n",
    "\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax2.scatter(v_spec, SA_stacked_lowJ, color='k', s=5)\n",
    "ax2.errorbar(v_spec, SA_stacked_lowJ, err_SA_stacked_lowJ, color='k', alpha=0.8, lw=0.5, capsize=2, linestyle=' ')\n",
    "ax2.axhline(0, color='purple', ls = '--', lw=2, zorder=0, alpha=0.7)\n",
    "\n",
    "ax1.set_xlim(-100, 100)\n",
    "ax2.set_xlim(-100, 100)\n",
    "\n",
    "#ax1.set_ylim(0.2, 1.3)\n",
    "ax2.set_ylim(-20, 20)\n",
    "\n",
    "\n",
    "### Plot design ###\n",
    "\n",
    "index_xticks = 25\n",
    "ax1.xaxis.set_major_locator(MultipleLocator(index_xticks))\n",
    "ax1.xaxis.set_minor_locator(MultipleLocator(index_xticks/4))\n",
    "ax2.xaxis.set_major_locator(MultipleLocator(index_xticks))\n",
    "ax2.xaxis.set_minor_locator(MultipleLocator(index_xticks/4))\n",
    "\n",
    "index_yticks1 =0.1 \n",
    "ax1.yaxis.set_major_locator(MultipleLocator(index_yticks1))\n",
    "ax1.yaxis.set_minor_locator(MultipleLocator(index_yticks1/4))\n",
    "\n",
    "index_yticks2 = 5\n",
    "ax2.yaxis.set_major_locator(MultipleLocator(index_yticks2))\n",
    "ax2.yaxis.set_minor_locator(MultipleLocator(index_yticks2/4))\n",
    "\n",
    "ax1.set_xticklabels([])\n",
    "ax1.tick_params(which='major',axis='both',right=True,top=True, labelsize=15, pad=7,width=2.5, length=6,direction='in',color='k')\n",
    "ax1.tick_params(which='minor',axis='both',right=True,top=True, labelsize=15, pad=7,width=2, length=3,direction='in',color='k')\n",
    "ax2.tick_params(which='major',axis='both',right=True,top=True, labelsize=15, pad=7,width=2.5, length=6,direction='in',color='k')\n",
    "ax2.tick_params(which='minor',axis='both',right=True,top=True, labelsize=15, pad=7,width=2, length=3,direction='in',color='k')\n",
    "\n",
    "ax2.set_xlabel('Velocity (km/s)', labelpad=10, fontsize=20)\n",
    "ax1.set_ylabel('Normalized flux', labelpad=10, fontsize=20)\n",
    "ax2.set_ylabel('SA (mas)', labelpad=10, fontsize=20)\n",
    "\n",
    "for side in ax1.spines.keys():  # 'top'\n",
    "        ax1.spines[side].set_linewidth(2)\n",
    "for side in ax2.spines.keys():  # 'top'\n",
    "        ax2.spines[side].set_linewidth(2)\n",
    "        \n",
    "plt.suptitle(f'{source} 12CO v=1-0 low-J {date}', fontsize=20, fontweight='bold')\n",
    "plt.savefig(path+f'figures/{source}_12COv=1-0_low-J_{date}.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = open(path+f'rectified/{source}_SA_lowJ_stacked_PA{PA1}_{PA2}.csv', 'w')\n",
    "csvfile.write('vel, flux_norm, err_flux_norm, SA, err_SA\\n')\n",
    "\n",
    "for i in range(v_spec.size):\n",
    "    csvfile.write(f'{v_spec[i]:.3f}, {flux_stacked_lowJ[i]:.5f}, {err_flux_stacked_lowJ[i]:.5f}, {SA_stacked_lowJ[i]:.5f}, {err_SA_stacked_lowJ[i]:.5f}\\n')\n",
    "    \n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wavelength range over which to look for lines\n",
    "wave_range = (np.nanmin(wave_flux)-np.nanmin(wave_flux)*0.001, np.nanmax(wave_flux)+np.nanmax(wave_flux)*0.001)\n",
    "\n",
    "# wavelength window (in microns) around the line to look for data (roughly corresponds to +/-30 km/s)\n",
    "delta_wave_signal = 5e-4\n",
    "\n",
    "# find the transitions where there is some signal\n",
    "trans_nums = 0\n",
    "trans_wave = []\n",
    "trans_ids = []\n",
    "for i, wave1 in enumerate(hitran_CO_1_0['wave']):\n",
    "    if hitran_CO_1_0['Qpp'][i].replace(' ','') in highJ:\n",
    "        if ((wave1 > wave_range[0]) & (wave1 < wave_range[1])):\n",
    "            # Select indices around the transitions\n",
    "            j = np.where((wave_flux > wave1-delta_wave_signal) & (wave_flux < wave1+delta_wave_signal))[0]\n",
    "            # Accept and save transitions and their ids for where we have signal (not everything is NaN)\n",
    "            if np.sum(np.isfinite(flux[j])) > 0:\n",
    "                trans_nums += 1\n",
    "                trans_wave.append(wave1)\n",
    "                trans_ids.append(hitran_CO_1_0['Qpp'][i].replace(' ',''))\n",
    "            \n",
    "# take snippets of each transition from +/-delta_v in km/s, sampled at 1 km/s\n",
    "# ~10% wider in wavelength to avoid interpolation issues\n",
    "delta_v = 120\n",
    "clight = 2.99792458e5\n",
    "delta_wave = 1.1 * 5 * delta_v / clight\n",
    "\n",
    "v_spec = np.arange(-delta_v, 1.01*delta_v, 1)\n",
    "nv = v_spec.size\n",
    "flux_stack_highJ = np.zeros(nv)\n",
    "weights_stack_flux_highJ = np.zeros(nv)\n",
    "    \n",
    "nrows = 8\n",
    "ncols = math.ceil(trans_nums / nrows)\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(18, 18))\n",
    "\n",
    "print(f'Stacking transitions:', end=' ')\n",
    "for i, wave1 in enumerate(trans_wave):\n",
    "    #print(i, wave1)\n",
    "    col = i % ncols\n",
    "    row = int(i / ncols)\n",
    "\n",
    "    j = np.where((wave_flux > wave1-delta_wave) & (wave_flux < wave1+delta_wave))[0]\n",
    "    v_wave = (wave_flux[j] / wave1 - 1) * clight\n",
    "    wave_plot = wave_flux[j]\n",
    "\n",
    "    flux_v = interp1d(v_wave, flux_norm[j], bounds_error=False)\n",
    "    flux_err = interp1d(v_wave, err_flux_norm[j], bounds_error=False)\n",
    "    #axs[row, col].plot(v_spec, flux_v(v_spec), color='b')\n",
    "    #axs[row, col].set_xlim(-delta_v, delta_v)\n",
    "\n",
    "    axs[row, col].plot(wave_plot, flux_norm[j], color='darkblue')\n",
    "    axs[row, col].set_xlim(wave1-delta_wave, wave1+delta_wave)\n",
    "    axs[row, col].axvline(wave1, color='C1', ls = '--')\n",
    "    axs[row, col].text(wave1+0.03*delta_wave, 0.6, trans_ids[i], rotation=90, fontsize=12, fontweight='bold', color='C1')\n",
    "\n",
    "    # plot any 13CO v=1-0 transitions within delta_wave of the 13CO line\n",
    "    for k, wave_CO10 in enumerate(hitran_13CO_1_0['wave']):\n",
    "        if np.abs(wave_CO10 - wave1) < delta_wave:\n",
    "            axs[row, col].axvline(wave_CO10, color='green', ls=':')\n",
    "            axs[row, col].text(wave_CO10+0.03*delta_wave, 0.6, hitran_CO_1_0['Qpp'][i].replace(' ',''), color='green', rotation=90)\n",
    "    #axs[row, col].set_ylim(0.2, 1.4)\n",
    "\n",
    "    # plot any CO v=2-1 transitions within delta_wave of the 13CO line\n",
    "    for k, wave_CO21 in enumerate(hitran_CO_2_1['wave']):\n",
    "        if np.abs(wave_CO21 - wave1) < delta_wave:\n",
    "            axs[row, col].axvline(wave_CO21, color='cyan', ls=':')\n",
    "            axs[row, col].text(wave_CO21+0.03*delta_wave, 0.6, hitran_CO_2_1['Qpp'][i].replace(' ',''), color='cyan', rotation=90)\n",
    "    #axs[row, col].set_ylim(0.2, 1.4)\n",
    "\n",
    "    # stacking without counting the NaNs\n",
    "    # do not include the following 13CO transitions since they are contaminated by some CO v=1-0 transitions\n",
    "    #bad_trans_v10 = ['R38','R35','R34','R33','R30','R29','R26','R25','R24','R21','R20','R19','R15','R14','R9','R8','R7','R2','R1','R0','P6','P13','P14','P15','P22','P23','P24','P33','P34']\n",
    "    #bad_trans_v21 = []\n",
    "    #bad_trans = bad_trans_v10 + bad_trans_v21\n",
    "    #if trans_ids[i] not in bad_trans:\n",
    "    \n",
    "    print(f'{trans_ids[i]},', end=' ')\n",
    "    # stacking without counting the NaNs\n",
    "    for j, v1 in enumerate(v_spec):\n",
    "        f = flux_v(v1)\n",
    "        e = flux_err(v1)\n",
    "        if np.isfinite(f) & np.isfinite(e):\n",
    "            w = 1/e**2\n",
    "            flux_stack_highJ[j] = flux_stack_highJ[j] + w * f\n",
    "            weights_stack_flux_highJ[j] = weights_stack_flux_highJ[j] + w\n",
    "\n",
    "    axs[row, col].set_ylim(0.5, 1.5)\n",
    "    #axs[row, col].axhline(1, color='k', ls=':')\n",
    "    axs[row, col].set_xlabel(r'$\\lambda$ ($\\mu$m)')\n",
    "    if col == 0:\n",
    "        axs[row, col].set_ylabel('Normalized flux')\n",
    "\n",
    "print(f'\\n')\n",
    "\n",
    "# don't show axes for panels where there is no data\n",
    "n_extra = nrows * ncols - len(trans_wave)\n",
    "if n_extra > 0:\n",
    "    for i in range(n_extra):\n",
    "        col = (nrows*ncols - i - 1) % ncols\n",
    "        row = int((nrows*ncols - i - 1) / ncols)\n",
    "        axs[row, col].axis('off')\n",
    "\n",
    "#plt.savefig('transitions.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wavelength range over which to look for lines\n",
    "wave_range = (np.nanmin(wave_SA)-np.nanmin(wave_SA)*0.001, np.nanmax(wave_SA)+np.nanmax(wave_SA)*0.001)\n",
    "\n",
    "# wavelength window (in microns) around the line to look for data (roughly corresponds to +/-30 km/s)\n",
    "delta_wave_signal = 5e-4\n",
    "\n",
    "# find the transitions where there is some signal\n",
    "trans_nums = 0\n",
    "trans_wave = []\n",
    "trans_ids = []\n",
    "for i, wave1 in enumerate(hitran_CO_1_0['wave']):\n",
    "    if hitran_CO_1_0['Qpp'][i].replace(' ','') in highJ:\n",
    "        if ((wave1 > wave_range[0]) & (wave1 < wave_range[1])):\n",
    "            # Select indices around the transitions\n",
    "            j = np.where((wave_SA > wave1-delta_wave_signal) & (wave_SA < wave1+delta_wave_signal))[0]\n",
    "            # Accept and save transitions and their ids for where we have signal (not everything is NaN)\n",
    "            if np.sum(np.isfinite(SA[j])) > 0:\n",
    "                trans_nums += 1\n",
    "                trans_wave.append(wave1)\n",
    "                trans_ids.append(hitran_CO_1_0['Qpp'][i].replace(' ',''))\n",
    "            \n",
    "# take snippets of each transition from +/-delta_v in km/s, sampled at 1 km/s\n",
    "# ~10% wider in wavelength to avoid interpolation issues\n",
    "delta_v = 120\n",
    "clight = 2.99792458e5\n",
    "delta_wave = 1.1 * 5 * delta_v / clight\n",
    "\n",
    "v_spec = np.arange(-delta_v, 1.01*delta_v, 1)\n",
    "nv = v_spec.size\n",
    "SA_stack_highJ = np.zeros(nv)\n",
    "weights_stack_SA_highJ = np.zeros(nv)\n",
    "    \n",
    "nrows = 2\n",
    "ncols = math.ceil(trans_nums / nrows)\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(18, 10))\n",
    "\n",
    "print(f'Stacking transitions:', end=' ')\n",
    "for i, wave1 in enumerate(trans_wave):\n",
    "    #print(i, wave1)\n",
    "    col = i % ncols\n",
    "    row = int(i / ncols)\n",
    "\n",
    "    j = np.where((wave_SA > wave1-delta_wave) & (wave_SA < wave1+delta_wave))[0]\n",
    "    v_wave = (wave_SA[j] / wave1 - 1) * clight\n",
    "    wave_plot = wave_SA[j]\n",
    "\n",
    "    SA_v = interp1d(v_wave, SA[j], bounds_error=False)\n",
    "    SA_err = interp1d(v_wave, err_SA[j], bounds_error=False)\n",
    "    #axs[row, col].plot(v_spec, SA_v(v_spec), color='b')\n",
    "    #axs[row, col].set_xlim(-delta_v, delta_v)\n",
    "\n",
    "    axs[row, col].plot(wave_plot, SA[j], color='k')\n",
    "    axs[row, col].set_xlim(wave1-delta_wave, wave1+delta_wave)\n",
    "    axs[row, col].axvline(wave1, color='C1', ls = '--')\n",
    "    axs[row, col].text(wave1+0.03*delta_wave, 0.6, trans_ids[i], rotation=90, fontsize=12, fontweight='bold', color='C1')\n",
    "\n",
    "    # plot any 13CO v=1-0 transitions within delta_wave of the 13CO line\n",
    "    for k, wave_CO10 in enumerate(hitran_13CO_1_0['wave']):\n",
    "        if np.abs(wave_CO10 - wave1) < delta_wave:\n",
    "            axs[row, col].axvline(wave_CO10, color='green', ls=':')\n",
    "            axs[row, col].text(wave_CO10+0.03*delta_wave, 0.6, hitran_CO_1_0['Qpp'][i].replace(' ',''), color='green', rotation=90)\n",
    "    #axs[row, col].set_ylim(0.2, 1.4)\n",
    "\n",
    "    # plot any CO v=2-1 transitions within delta_wave of the 13CO line\n",
    "    for k, wave_CO21 in enumerate(hitran_CO_2_1['wave']):\n",
    "        if np.abs(wave_CO21 - wave1) < delta_wave:\n",
    "            axs[row, col].axvline(wave_CO21, color='cyan', ls=':')\n",
    "            axs[row, col].text(wave_CO21+0.03*delta_wave, 0.6, hitran_CO_2_1['Qpp'][i].replace(' ',''), color='cyan', rotation=90)\n",
    "    #axs[row, col].set_ylim(0.2, 1.4)\n",
    "\n",
    "    # stacking without counting the NaNs\n",
    "    # do not include the following 13CO transitions since they are contaminated by some CO v=1-0 transitions\n",
    "    #bad_trans_v10 = ['R38','R35','R34','R33','R30','R29','R26','R25','R24','R21','R20','R19','R15','R14','R9','R8','R7','R2','R1','R0','P6','P13','P14','P15','P22','P23','P24','P33','P34']\n",
    "    #bad_trans_v21 = []\n",
    "    #bad_trans = bad_trans_v10 + bad_trans_v21\n",
    "    #if trans_ids[i] not in bad_trans:\n",
    "    \n",
    "    print(f'{trans_ids[i]},', end=' ')\n",
    "    # stacking without counting the NaNs\n",
    "    for j, v1 in enumerate(v_spec):\n",
    "        f = SA_v(v1)\n",
    "        e = SA_err(v1)\n",
    "        if np.isfinite(f) & np.isfinite(e):\n",
    "            w = 1/e**2\n",
    "            SA_stack_highJ[j] = SA_stack_highJ[j] + w * f\n",
    "            weights_stack_SA_highJ[j] = weights_stack_SA_highJ[j] + w\n",
    "\n",
    "    axs[row, col].set_ylim(-20, 20)\n",
    "    #axs[row, col].axhline(1, color='k', ls=':')\n",
    "    axs[row, col].set_xlabel(r'$\\lambda$ ($\\mu$m)')\n",
    "    if col == 0:\n",
    "        axs[row, col].set_ylabel('SA (mas)')\n",
    "\n",
    "print(f'\\n')\n",
    "\n",
    "# don't show axes for panels where there is no data\n",
    "n_extra = nrows * ncols - len(trans_wave)\n",
    "if n_extra > 0:\n",
    "    for i in range(n_extra):\n",
    "        col = (nrows*ncols - i - 1) % ncols\n",
    "        row = int((nrows*ncols - i - 1) / ncols)\n",
    "        axs[row, col].axis('off')\n",
    "\n",
    "#plt.savefig('transitions.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_stacked_highJ = flux_stack_highJ / weights_stack_flux_highJ\n",
    "err_flux_stacked_highJ = 1/np.sqrt(weights_stack_flux_highJ)\n",
    "\n",
    "SA_stacked_highJ = SA_stack_highJ / weights_stack_SA_highJ\n",
    "err_SA_stacked_highJ = 1/np.sqrt(weights_stack_SA_highJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0., hspace=0.07)\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.plot(v_spec, flux_stacked_highJ, color='mediumblue', lw=2)\n",
    "ax1.fill_between(v_spec, flux_stacked_highJ - err_flux_stacked_highJ, flux_stacked_highJ + err_flux_stacked_highJ, color='mediumblue', alpha=0.3)\n",
    "#ax.set_xlabel('Velocity (km/s)')\n",
    "\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax2.scatter(v_spec, SA_stacked_highJ, color='k', s=5)\n",
    "ax2.errorbar(v_spec, SA_stacked_highJ, err_SA_stacked_highJ, color='k', alpha=0.8, lw=0.5, capsize=2, linestyle=' ')\n",
    "ax2.axhline(0, color='purple', ls = '--', lw=2, zorder=0, alpha=0.7)\n",
    "\n",
    "ax1.set_xlim(-100, 100)\n",
    "ax2.set_xlim(-100, 100)\n",
    "\n",
    "#ax1.set_ylim(0.2, 1.3)\n",
    "ax2.set_ylim(-10, 10)\n",
    "\n",
    "\n",
    "### Plot design ###\n",
    "\n",
    "index_xticks = 25\n",
    "ax1.xaxis.set_major_locator(MultipleLocator(index_xticks))\n",
    "ax1.xaxis.set_minor_locator(MultipleLocator(index_xticks/4))\n",
    "ax2.xaxis.set_major_locator(MultipleLocator(index_xticks))\n",
    "ax2.xaxis.set_minor_locator(MultipleLocator(index_xticks/4))\n",
    "\n",
    "index_yticks1 = 0.05 \n",
    "ax1.yaxis.set_major_locator(MultipleLocator(index_yticks1))\n",
    "ax1.yaxis.set_minor_locator(MultipleLocator(index_yticks1/4))\n",
    "\n",
    "index_yticks2 = 5\n",
    "ax2.yaxis.set_major_locator(MultipleLocator(index_yticks2))\n",
    "ax2.yaxis.set_minor_locator(MultipleLocator(index_yticks2/4))\n",
    "\n",
    "ax1.set_xticklabels([])\n",
    "ax1.tick_params(which='major',axis='both',right=True,top=True, labelsize=15, pad=7,width=2.5, length=6,direction='in',color='k')\n",
    "ax1.tick_params(which='minor',axis='both',right=True,top=True, labelsize=15, pad=7,width=2, length=3,direction='in',color='k')\n",
    "ax2.tick_params(which='major',axis='both',right=True,top=True, labelsize=15, pad=7,width=2.5, length=6,direction='in',color='k')\n",
    "ax2.tick_params(which='minor',axis='both',right=True,top=True, labelsize=15, pad=7,width=2, length=3,direction='in',color='k')\n",
    "\n",
    "ax2.set_xlabel('Velocity (km/s)', labelpad=10, fontsize=20)\n",
    "ax1.set_ylabel('Normalized flux', labelpad=10, fontsize=20)\n",
    "ax2.set_ylabel('SA (mas)', labelpad=10, fontsize=20)\n",
    "\n",
    "for side in ax1.spines.keys():  # 'top'\n",
    "        ax1.spines[side].set_linewidth(2)\n",
    "for side in ax2.spines.keys():  # 'top'\n",
    "        ax2.spines[side].set_linewidth(2)\n",
    "\n",
    "plt.suptitle(f'{source} 12CO v=1-0 high-J {date}', fontsize=20, fontweight='bold')\n",
    "plt.savefig(path+f'figures/{source}_12COv=1-0_high-J_{date}.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = open(path+f'rectified/{source}_SA_highJ_stacked_PA{PA1}_{PA2}.csv', 'w')\n",
    "csvfile.write('vel, flux_norm, err_flux_norm, SA, err_SA\\n')\n",
    "\n",
    "for i in range(v_spec.size):\n",
    "    csvfile.write(f'{v_spec[i]:.3f}, {flux_stacked_highJ[i]:.5f}, {err_flux_stacked_highJ[i]:.5f}, {SA_stacked_highJ[i]:.5f}, {err_SA_stacked_highJ[i]:.5f}\\n')\n",
    "    \n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
