{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the SA signal for each order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from astropy.io import ascii, fits\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from scipy import interpolate\n",
    "from astropy.visualization import MinMaxInterval, AsinhStretch, HistEqStretch, ImageNormalize\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import median_abs_deviation\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the directory containing the combined rectified and cal files\n",
    "path = '/Users/jpw/Analysis/NIRSPEC/iSHELL/240107/'\n",
    "path = '/Volumes/JPW_2TB/iSHELL/230630/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load atmospheric transmission file\n",
    "hdu = fits.open('/Users/jpw/idl/Spextool/data/atran75000.fits')\n",
    "tdata = hdu[0].data\n",
    "atrans = interpolate.interp1d(tdata[0,:], tdata[1,:])\n",
    "hdu.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "j1 = 30           # starting point of first order -- figured out by hand\n",
    "dj_AB = 121       # width of each order -- this should match the size of the number of rows in the order extension\n",
    "dj_blank = 30     # gap between orders -- this is figured out by eye and assumed to be the same for all orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two gaussians with different peaks and offsets but same FWHM\n",
    "# added an extra constant offset since some orders are not perfectly sky-subtracted\n",
    "def gauss2(x, A1, x1, A2, x2, fwhm, C):\n",
    "    sigma = fwhm / np.sqrt(8*np.log(2))\n",
    "    y = A1 * np.exp(-0.5*((x-x1)/sigma)**2) + A2 * np.exp(-0.5*((x-x2)/sigma)**2) + C\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_median(order_flux, pix_nofit=0, plotfile=None):\n",
    "    # stack an order in wavelength to measure the average slit profile and guide individual fits\n",
    "    im_median = np.nanmedian(order_flux, axis=1)\n",
    "    j = np.arange(im_median.size)\n",
    "    p0 = [np.min(im_median), np.argmin(im_median), np.max(im_median), np.argmax(im_median), 2, 0]\n",
    "\n",
    "    # don't fit within s_nofit of the edges\n",
    "    fit_range = (j > pix_nofit) & (j < j[-1]-pix_nofit)\n",
    "\n",
    "    # fit two gaussians to the data\n",
    "    pfit, pcov = curve_fit(gauss2, j[fit_range], im_median[fit_range], p0)\n",
    "    perr = np.sqrt(np.diag(pcov))\n",
    "\n",
    "    if plotfile is not None:\n",
    "        fig, ax = plt.subplots(figsize=(8, 4))\n",
    "        ax.step(j, im_median)\n",
    "        ax.plot(j[fit_range], gauss2(j[fit_range], *pfit))\n",
    "        ax.set_xlabel(r\"Row (pixels)\", fontsize=14)\n",
    "        ax.set_ylabel(r\"Flux (Jy)\", fontsize=14)\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(plotfile, dpi=300)\n",
    "\n",
    "    return pfit, perr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hot_pixels(order_flux, order_var, MAD_factor=20):\n",
    "    # creating a mask on the variance image, putting to False all pixels that for each column are outside 5 sigma\n",
    "    mask_var = np.full(order_var.shape, True)\n",
    "    for i in range(order_var.shape[1]):\n",
    "        column = np.nan_to_num(order_var[:,i])\n",
    "        median = np.nanmedian(column)\n",
    "        MAD = median_abs_deviation(column)    # Median Absolutet Deviation, much better than standard deviation since it's not influenced by outliers\n",
    "        mask_column = np.logical_and(column>0, column<median+MAD_factor*MAD)    # 20 seems like a not too aggressive value\n",
    "        mask_var[:,i] = mask_column\n",
    "\n",
    "    # converting the mask from boolean to 0 and 1\n",
    "    mask_var = np.array(mask_var, dtype=int)\n",
    "    # convert zeros to NaNs\n",
    "    mask_var = mask_var.astype(float)\n",
    "    mask_var[mask_var==0] = np.nan\n",
    "    \n",
    "    order_flux_masked = order_flux*mask_var\n",
    "    order_var_masked = order_var*mask_var\n",
    "    \n",
    "    return order_flux_masked, order_var_masked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$SA = \\mu - \\mu_\\mathrm{MED}$ \n",
    "\n",
    "where \n",
    "\n",
    "$\\mu = \\frac{\\sum_{i=0}^N y_i F_i}{\\sum_{i=0}^N F_i}$ for each column\n",
    "\n",
    "$\\mu_\\mathrm{MED}$ is the median value of $\\mu$ within a horizontal window of M pixels\n",
    "\n",
    "\n",
    "#### Uncertainties\n",
    "\n",
    "$\\Delta SA = \\Delta \\mu + \\Delta \\mu_\\mathrm{MED}$\n",
    "\n",
    "where\n",
    "\n",
    "$\\Delta \\mu   = \\left(\\sum_{j=0}^N \\left | \\frac{y_j \\left(\\sum_{i=0}^N F_i \\right) - \\left(\\sum_{i=0}^N y_i F_i \\right)}{\\left(\\sum_{i=0}^N F_i \\right)^2}  \\right |  \\Delta F_j\\right) \\frac{1}{\\sqrt{N}} $ \n",
    "\n",
    "with $\\Delta F_j\\$ the error in the flux associated to each pixel\n",
    "\n",
    "and \n",
    "\n",
    "$\\Delta \\mu_\\mathrm{MED} = 1.253 \\frac{\\Delta \\mu}{\\sqrt{M}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mu(order_flux, order_var, pix_nofit=0, nfwhm=1, C=1.,  verbose=False):\n",
    "    ny, nx = order_flux.shape\n",
    "    order_std = np.sqrt(order_var)\n",
    "    \n",
    "    # Fitting Gaussians to have the fwhm\n",
    "    pfit, perr = fit_median(order_flux, pix_nofit=0) #, plotfile=path+source+'_fit_median.png')\n",
    "    jneg =  pfit[1] + np.array([0, -0.5*nfwhm, 0.5*nfwhm]) * pfit[4]\n",
    "    jpos =  pfit[3] + np.array([0, -0.5*nfwhm, 0.5*nfwhm]) * pfit[4]\n",
    "    \n",
    "    # Creating arrays\n",
    "    mu_neg, mu_neg_err = np.zeros(nx), np.zeros(nx)   \n",
    "    mu_pos, mu_pos_err = np.zeros(nx), np.zeros(nx)\n",
    "    \n",
    "    for i in range(nx):\n",
    "        \n",
    "        #############\n",
    "        ### Calculating the mean of the vertical position for each column weighted by the pixel flux \n",
    "        #############\n",
    "        \n",
    "        # Negative\n",
    "        flux_slice_neg = order_flux[int(np.around(jneg[1])): int(np.around(jneg[2]))+1, i]\n",
    "        std_slice_neg = order_std[int(np.around(jneg[1])): int(np.around(jneg[2]))+1, i]\n",
    "        yarr_neg = np.arange(int(np.around(jneg[1])), int(np.around(jneg[2]))+1)\n",
    "        \n",
    "        num = np.nansum(yarr_neg*flux_slice_neg)\n",
    "        den = np.nansum(flux_slice_neg) \n",
    "        mu_neg[i] = num / den\n",
    "        \n",
    "        # Uncertainty\n",
    "        der = (yarr_neg*den-num)/den**2\n",
    "        mu_neg_err[i] = np.nansum(np.abs(der)*std_slice_neg) * 1/np.sqrt(yarr_neg.size)\n",
    "    \n",
    "    \n",
    "        \n",
    "        # Positive\n",
    "        flux_slice_pos = order_flux[int(np.around(jpos[1])): int(np.around(jpos[2]))+1, i]\n",
    "        std_slice_pos = order_std[int(np.around(jpos[1])): int(np.around(jpos[2]))+1, i]\n",
    "        yarr_pos = np.arange(int(np.around(jpos[1])), int(np.around(jpos[2]))+1)\n",
    "        \n",
    "        num = np.nansum(yarr_pos*flux_slice_pos)\n",
    "        den = np.nansum(flux_slice_pos)\n",
    "        mu_pos[i] = num / den\n",
    "        \n",
    "        # Uncertainty\n",
    "        der = (yarr_pos*den-num)/den**2\n",
    "        mu_pos_err[i] = np.nansum(np.abs(der)*std_slice_pos) * 1/np.sqrt(yarr_pos.size)\n",
    "    \n",
    "    return mu_neg, mu_pos, mu_neg_err, mu_pos_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_muMED(arr, arr_err, w):\n",
    "    # Median filter 1D array arr over a window size w in pixels\n",
    "\n",
    "    n = arr.size\n",
    "    arr_filter, arr_fiter_err = np.zeros(n), np.zeros(n)\n",
    "    \n",
    "    # Define the window\n",
    "    for i in range(n):\n",
    "        \n",
    "        # Left edge\n",
    "        if i<int((w-1)/2):\n",
    "            arr_window = arr[:i+1+int((w-1)/2)] \n",
    "        # Central pixels\n",
    "        if int((w-1)/2)<= i < int(n - (w-1)/2):\n",
    "            arr_window = arr[i-int((w-1)/2):i+1+int((w-1)/2)]\n",
    "        # Right edge\n",
    "        if i>=int(n - (w-1)/2):\n",
    "            arr_window = arr[i-int((w-1)/2):] \n",
    "            \n",
    "        arr_filter[i] = np.nanmedian(arr_window)\n",
    "        arr_fiter_err[i] = 1.253 * arr_err[i]/np.sqrt(arr_window.size)\n",
    "    \n",
    "    return arr_filter, arr_fiter_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_SA(mu, mu_err, muMED, muMED_err):\n",
    "    nx = mu.size\n",
    "    SA  = np.zeros((2, nx)) + np.nan\n",
    "\n",
    "    SA[0] = mu - muMED\n",
    "    SA[1] = mu_err + muMED_err\n",
    "    \n",
    "    return SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Elias24_PA136\n",
      "Order = 114, Min/Max wavelength = 4.509217059629072, 4.547327670478346\n",
      "Order = 113, Min/Max wavelength = 4.548980656038084, 4.587426797393182\n",
      "Order = 112, Min/Max wavelength = 4.589453823346046, 4.628245758975768\n",
      "Order = 111, Min/Max wavelength = 4.630655739154617, 4.669804010227063\n",
      "Order = 110, Min/Max wavelength = 4.672606278433143, 4.712121713602966\n",
      "Order = 109, Min/Max wavelength = 4.715326045508029, 4.7552197714664\n",
      "Order = 108, Min/Max wavelength = 4.758836407829275, 4.7991198603422855\n",
      "Order = 107, Min/Max wavelength = 4.803159531630485, 4.8438444670933505\n",
      "Order = 106, Min/Max wavelength = 4.848318419607356, 4.8894169271436345\n",
      "Order = 105, Min/Max wavelength = 4.894336950749226, 4.935861464886195\n",
      "Order = 104, Min/Max wavelength = 4.941239922468601, 4.98320323642202\n",
      "Order = 103, Min/Max wavelength = 4.989053095184825, 5.031468374788592\n",
      "Order = 102, Min/Max wavelength = 5.037803239530333, 5.080684037848972\n",
      "Order = 101, Min/Max wavelength = 5.087518186361218, 5.13087845902575\n",
      "Order = 100, Min/Max wavelength = 5.138226879768448, 5.182081001079061\n",
      "Order = 99, Min/Max wavelength = 5.189959433301879, 5.233640374360173\n",
      "----------------------------------------\n",
      "Elias24_PA316\n",
      "Order = 114, Min/Max wavelength = 4.509217302655764, 4.54732707108325\n",
      "Order = 113, Min/Max wavelength = 4.548976383500487, 4.587424351286536\n",
      "Order = 112, Min/Max wavelength = 4.589445957739748, 4.628241769129411\n",
      "Order = 111, Min/Max wavelength = 4.630645227907532, 4.669798787801263\n",
      "Order = 110, Min/Max wavelength = 4.672594094812141, 4.712115578244178\n",
      "Order = 109, Min/Max wavelength = 4.715313189567155, 4.7552130516187\n",
      "Order = 108, Min/Max wavelength = 4.758823907401867, 4.799112893573196\n",
      "Order = 107, Min/Max wavelength = 4.803148443367659, 4.843837600434915\n",
      "Order = 106, Min/Max wavelength = 4.848309830065456, 4.889410517449557\n",
      "Order = 105, Min/Max wavelength = 4.894331977529085, 4.93585587920601\n",
      "Order = 104, Min/Max wavelength = 4.941239715409555, 4.983198852393231\n",
      "Order = 103, Min/Max wavelength = 4.989058837616696, 5.031465581047862\n",
      "Order = 102, Min/Max wavelength = 5.0378161495867735, 5.080683234463459\n",
      "Order = 101, Min/Max wavelength = 5.087539518358094, 5.130880057945803\n",
      "Order = 100, Min/Max wavelength = 5.138257925651122, 5.182085426613544\n",
      "Order = 99, Min/Max wavelength = 5.190001524165595, 5.233645609974582\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# read in the source and wavecal from the manually edited sourcefile.txt\n",
    "with open(path+'rectified/sourcelist.txt') as f:\n",
    "    all_lines = f.read()\n",
    "lines = all_lines.split('\\n')\n",
    "\n",
    "# find the breakpoints between sources\n",
    "nbreak = []\n",
    "for nline, line1 in enumerate(lines):\n",
    "    if line1[0:4] == '----':\n",
    "        nbreak.append(nline)\n",
    "        \n",
    "#select window size in pixels for median filter \n",
    "median_window_pixel_size = 300\n",
    "\n",
    "# loop through the sources\n",
    "print('-'*40)\n",
    "for n1 in range(len(nbreak)-1):\n",
    "    source = lines[nbreak[n1]+1]\n",
    "    calfile = lines[nbreak[n1]+2]\n",
    "\n",
    "    hdu1 = fits.open(path+'rectified/'+source+'_rectified.fits')\n",
    "    flux = hdu1[0].data\n",
    "    var = hdu1[1].data\n",
    "    nslit, nwl = flux.shape\n",
    "\n",
    "    hdu2 = fits.open(path+'cal/'+calfile)\n",
    "    wc_hd = hdu2[0].header\n",
    "    orders = wc_hd['ORDERS'].split(',')\n",
    "\n",
    "    csvfile = open(path+'rectified/'+source+'_SA.csv', 'w')\n",
    "    csvfile.write('wavelength,  off_neg, off_pos, err_neg, err_pos\\n')\n",
    "\n",
    "    # loop through the orders in reverse order so that the wavelength monotonically increases\n",
    "    print(source)\n",
    "    \n",
    "    for n, order in enumerate(orders[::-1]):\n",
    "        norder = len(orders) - n - 1\n",
    "        j0 = j1 + (dj_AB + dj_blank) * norder\n",
    "\n",
    "        wavecal = hdu2[3+norder].data\n",
    "        wl_arr = wavecal[0, 0, 1:]\n",
    "        print(f'Order = {order}, Min/Max wavelength = {wl_arr.min()}, {wl_arr.max()}')\n",
    "        \n",
    "        # Select and clean (remove hot pixels) orders\n",
    "        order_flux = flux[j0:j0+dj_AB, :wl_arr.size]\n",
    "        order_var = var[j0:j0+dj_AB, :wl_arr.size]\n",
    "        order_flux_masked, order_var_masked = remove_hot_pixels(order_flux, order_var, MAD_factor=30)\n",
    "\n",
    "        # Calculate mu and its error\n",
    "        mu_neg, mu_pos, mu_neg_err, mu_pos_err = calculate_mu(order_flux_masked, order_var_masked, pix_nofit=0, nfwhm=3)\n",
    "        \n",
    "        # Calculate mu_MED and its error\n",
    "        muMED_neg, muMED_neg_err = calculate_muMED(mu_neg, mu_neg_err, median_window_pixel_size)\n",
    "        muMED_pos, muMED_pos_err = calculate_muMED(mu_pos, mu_pos_err, median_window_pixel_size)\n",
    "        \n",
    "        # Calculate SA and its error\n",
    "        SA_neg = calculate_SA(mu_neg, mu_neg_err, muMED_neg, muMED_neg_err)\n",
    "        SA_pos = calculate_SA(mu_pos, mu_pos_err, muMED_pos, muMED_pos_err)\n",
    "        \n",
    "        flag = atrans(wl_arr) < 0.3\n",
    "        SA_neg[:, flag] = np.nan\n",
    "        SA_pos[:, flag] = np.nan\n",
    "\n",
    "        for i in range(wl_arr.size):\n",
    "            csvfile.write(f'{wl_arr[i]:11.9f}, {SA_neg[0, i]:7.4f}, {SA_pos[0, i]:7.4f}, {SA_neg[1, i]:7.4f}, {SA_pos[1, i]:7.4f}\\n')\n",
    "\n",
    "    print('-'*40)\n",
    "    hdu1.close()\n",
    "    hdu2.close()\n",
    "    csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
